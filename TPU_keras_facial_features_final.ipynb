{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TPU-keras-facial-features-final",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dataSci-rigo/facial_feature_estimation_from_scratch/blob/master/TPU_keras_facial_features_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "siY3qelwkGpA",
        "colab_type": "code",
        "outputId": "e294be3a-76ae-4209-de3f-6e9b160903bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import matplotlib.pyplot as plt\n",
        "!pip install pillow\n",
        "np.random.seed(0)\n",
        "import tensorflow as tf\n",
        "from  tensorflow import keras\n",
        "import keras.callbacks as callbacks\n",
        "\n",
        "from keras.callbacks import EarlyStopping "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (4.3.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow) (0.46)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsfXDLB76OLx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "#drive=GoogleDrive(4/iQEapMjjZP0ngyzZdGQsb1VhT8Hy3GEhw3R3CHr4yo4GFPHi08aFUUk)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TcP_9q5m6Plm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_shareable_link=\"https://drive.google.com/file/d/1HB3mJo_2EVewP9oqHtlcDCfw6y01om63/view?usp=sharing\"\n",
        "train_shareable_link='https://drive.google.com/file/d/1DiE4w94eJDEXxn87npDd5o6Y3QFdzzIU/view?usp=sharing'\n",
        "\n",
        "test_csv_link = 'https://drive.google.com/open?id=1HB3mJo_2EVewP9oqHtlcDCfw6y01om63' # shareable link\n",
        "train_csv_link = 'https://drive.google.com/open?id=1DiE4w94eJDEXxn87npDd5o6Y3QFdzzIU' # shareable link\n",
        "\n",
        "_, test_id = test_csv_link.split('=')\n",
        "_, train_id = train_csv_link.split('=')\n",
        "# print (test_id) # Verify that you have everything after '='\n",
        "# print (train_id) # Verify that you have everything after '='\n",
        "\n",
        "downloaded_test = drive.CreateFile({'id':test_id})\n",
        "downloaded_train = drive.CreateFile({'id':train_id}) \n",
        "downloaded_test.GetContentFile('test.csv')\n",
        "downloaded_train.GetContentFile('train.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_uGIBZMBHy0",
        "colab_type": "text"
      },
      "source": [
        "# **EDA**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZLblk3E7in5",
        "colab_type": "code",
        "outputId": "b928f714-3ed2-4ba6-d49e-bab75dea7407",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "train_df = pd.read_csv('train.csv')\n",
        "test_df = pd.read_csv('test.csv')\n",
        "print(\"train shape: {}\".format(train_df.shape))\n",
        "print(\"test shape: {}\".format(test_df.shape))\n",
        "\n",
        "# Convert Image from string to np array of floats between 0 and 1\n",
        "train_df.Image = train_df.Image.apply(lambda x: np.array(object=x.split(' '), \n",
        "                                                         dtype=float)) / 255\n",
        "test_df.Image = test_df.Image.apply(lambda x: np.array(object=x.split(' '), \n",
        "                                                       dtype=float)) / 255"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train shape: (7049, 31)\n",
            "test shape: (1783, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "If-Itcpgmm_j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install impyute\n",
        "#from impyute.imputation.cs import mice\n",
        "\n",
        "# start the MICE training\n",
        "\n",
        "#imputed_training_mice=mice(train_features_cnn.astype(float))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1PeYv9xnIiV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_test_multiple(predicted_points,image, pics):\n",
        "  '''shows predicted features on image\n",
        "  \n",
        "  requires:\n",
        "  - test_images'''\n",
        "  x_points = []\n",
        "  y_points = []\n",
        "\n",
        "  # split into x coords and y coords\n",
        "  \n",
        "  for index, pic in enumerate(pics):\n",
        "    for i in range(15):\n",
        "      x_points.append(predicted_points[pic][i*2])\n",
        "      y_points.append(predicted_points[pic][i*2+1])\n",
        "\n",
        "    ax = plt.subplot(1,len(pics),index+1)\n",
        "    ax.imshow(image[pic].reshape(96,96),cmap='gray')\n",
        "    ax.scatter(x=x_points, y=y_points, c='r', s=20)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XWqUK1aCtbdg",
        "colab_type": "text"
      },
      "source": [
        "## **Forward Fill Missing Data**\n",
        "\n",
        "Since the data has multiple columns of missing information we are going to input them using the forward fill method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvx7laOFtgrb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "train_images_dirty=np.concatenate(np.array(train_df.Image.values)).ravel().reshape(train_df.shape[0],96,96,1)\n",
        "train_features_dirty=np.array(train_df.values)[:,0:30]\n",
        "\n",
        "train_df_clean=train_df.dropna(axis=0, how='any', thresh=None, subset=None, inplace=False)\n",
        "test_df_clean=test_df.dropna(axis=0, how='any', thresh=None, subset=None, inplace=False)\n",
        "train_images_clean=np.concatenate(np.array(train_df_clean.Image.values)).ravel().reshape(train_df_clean.shape[0],96,96,1)\n",
        "train_features_clean=np.array(train_df_clean.values)[:,0:30]\n",
        "\n",
        "#\"There may be regression problems in which the target value has a spread of values and when predicting a large value, you may not want to punish a model as heavily as mean squared error.\"\n",
        "# 'mean_squared_logarithmic_error'\n",
        "\n",
        "'''DataFrame.fillna(self, value=None, method=None, axis=None, inplace=False, limit=None, downcast=None, **kwargs)'''\n",
        "train_df_neg=train_df.fillna(value=0)\n",
        "test_df_neg=test_df.fillna(value=0)\n",
        "test_images_zero=np.concatenate(np.array(test_df_neg[\"Image\"].values)).ravel().reshape(test_df_neg.shape[0],96,96,1)\n",
        "train_images_zero=np.concatenate(np.array(train_df_neg.Image.values)).ravel().reshape(train_df_neg.shape[0],96,96,1)\n",
        "train_features_zero=np.array(train_df_neg.values)[:,0:30]\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Un88YdXRG3jn",
        "colab_type": "code",
        "outputId": "adaa9d61-f700-4cf4-ebdb-0e35f6ad5d1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        }
      },
      "source": [
        "image=[2289,2284]; plot_test_multiple(train_features_dirty,train_images_dirty, image)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAC7CAYAAAB1qmWGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nA5u3NnxnGgowAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4_F9ybDs828",
        "colab_type": "text"
      },
      "source": [
        "# **Split train into train/dev sets**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izCfhrGutX7i",
        "colab_type": "text"
      },
      "source": [
        "# **keras Model**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCFy4bkJIimm",
        "colab_type": "text"
      },
      "source": [
        "### keras Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUKU13Pt8Jvu",
        "colab_type": "code",
        "outputId": "574a4ec6-1200-4df0-c986-406c9091433e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "#!pip install pyyaml\n",
        "#!pip install tensorflow --upgrade\n",
        "import tensorflow as tf\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "print(tf.reduce_sum(tf.random.normal([1000, 1000])))\n",
        "#! pip install keras --upgrade\n",
        "\n",
        "from tensorflow.keras.models import save_model, load_model\n",
        "#save_model(model,'124446.model')\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "\n",
        "\n",
        "from google.colab import files\n",
        "from tensorflow.keras import callbacks"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"Sum:0\", shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLKrM1d_fbyX",
        "colab_type": "code",
        "outputId": "b9a05e2f-3f7b-41b6-9478-b0275f712544",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 733
        }
      },
      "source": [
        "%pip install tensorflow==1.13.1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.13.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/77/63/a9fa76de8dffe7455304c4ed635be4aa9c0bacef6e0633d87d5f54530c5c/tensorflow-1.13.1-cp36-cp36m-manylinux1_x86_64.whl (92.5MB)\n",
            "\u001b[K     || 92.5MB 282kB/s \n",
            "\u001b[?25hCollecting tensorboard<1.14.0,>=1.13.0 (from tensorflow==1.13.1)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/39/bdd75b08a6fba41f098b6cb091b9e8c7a80e1b4d679a581a0ccd17b10373/tensorboard-1.13.1-py3-none-any.whl (3.2MB)\n",
            "\u001b[K     || 3.2MB 36.8MB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator<1.14.0rc0,>=1.13.0 (from tensorflow==1.13.1)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/48/13f49fc3fa0fdf916aa1419013bb8f2ad09674c275b4046d5ee669a46873/tensorflow_estimator-1.13.0-py2.py3-none-any.whl (367kB)\n",
            "\u001b[K     || 368kB 48.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (1.1.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (0.2.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (1.16.4)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (0.33.4)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (1.12.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (3.7.1)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (0.7.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (1.15.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (0.8.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (1.0.8)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (0.15.5)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (3.1.1)\n",
            "Collecting mock>=2.0.0 (from tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow==1.13.1)\n",
            "  Downloading https://files.pythonhosted.org/packages/05/d2/f94e68be6b17f46d2c353564da56e6fb89ef09faeeff3313a046cb810ca9/mock-3.0.5-py2.py3-none-any.whl\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.13.1) (41.2.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.13.1) (2.8.0)\n",
            "\u001b[31mERROR: tensorflow-gpu 1.14.0 has requirement tensorboard<1.15.0,>=1.14.0, but you'll have tensorboard 1.13.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-gpu 1.14.0 has requirement tensorflow-estimator<1.15.0rc0,>=1.14.0rc0, but you'll have tensorflow-estimator 1.13.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorboard, mock, tensorflow-estimator, tensorflow\n",
            "  Found existing installation: tensorboard 1.14.0\n",
            "    Uninstalling tensorboard-1.14.0:\n",
            "      Successfully uninstalled tensorboard-1.14.0\n",
            "  Found existing installation: tensorflow-estimator 1.14.0\n",
            "    Uninstalling tensorflow-estimator-1.14.0:\n",
            "      Successfully uninstalled tensorflow-estimator-1.14.0\n",
            "  Found existing installation: tensorflow 1.14.0\n",
            "    Uninstalling tensorflow-1.14.0:\n",
            "      Successfully uninstalled tensorflow-1.14.0\n",
            "Successfully installed mock-3.0.5 tensorboard-1.13.1 tensorflow-1.13.1 tensorflow-estimator-1.13.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tensorboard",
                  "tensorflow",
                  "tensorflow_estimator"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpNnclPImIx3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_Model():\n",
        "  inputs=layers.Input(shape=(96, 96, 1))\n",
        "  batch=layers.BatchNormalization(input_shape=(96, 96, 1))(inputs)\n",
        "  layer1_1=layers.Conv2D(24, (5, 5), padding=\"same\", kernel_initializer='he_normal', activation='relu', input_shape=(96, 96, 1),data_format=\"channels_last\")(batch)\n",
        "  layer1_2=layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid')(layer1_1)\n",
        "\n",
        "  layer2_1=layers.Conv2D(36,(5,5), activation='relu')(layer1_2)\n",
        "  layer2_2=layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid')(layer2_1)\n",
        "\n",
        "  layer3_1=layers.Conv2D(48,(5,5) , activation='relu')(layer2_2)\n",
        "  layer3_2=layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid')(layer3_1)\n",
        "\n",
        "  layer4_1=layers.Conv2D(64,(3,3) , activation='relu')(layer3_2)\n",
        "  layer4_2=layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid')(layer4_1)\n",
        "\n",
        "  layer5_1=layers.Conv2D(64,(3,3), activation='relu')(layer4_2)\n",
        "  layer5_2=layers.GlobalAveragePooling2D()(layer5_1)\n",
        "\n",
        "  layerD_1=layers.Dense(500, activation='relu')(layer5_2)\n",
        "  layerD_2=layers.Dense(90, activation='relu')(layerD_1)\n",
        "  out=layers.Dense(30)(layerD_2)\n",
        " \n",
        "  return Model(inputs=inputs,outputs=out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VVwVA3-51J_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_sequential_model():\n",
        "  model = layers.Sequential([\n",
        "\n",
        "  layers.BatchNormalization(input_shape=(96, 96, 1)),\n",
        "  layers.Conv2D(24, (5, 5), padding=\"same\", kernel_initializer='he_normal', activation='relu', input_shape=(96, 96, 1),data_format=\"channels_last\"),\n",
        "  layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid'),\n",
        "\n",
        "  layers.Conv2D(36,(5,5), activation='relu'),\n",
        "  layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid'),\n",
        "\n",
        "  layers.Conv2D(48,(5,5) , activation='relu'),\n",
        "  layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid'),\n",
        "\n",
        "  layers.Conv2D(64,(3,3) , activation='relu'),\n",
        "  layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid'),\n",
        "\n",
        "  layers.Conv2D(64,(3,3), activation='relu') ,\n",
        "  layers.GlobalAveragePooling2D(),\n",
        "\n",
        "  layers.Dense(500, activation='relu'),\n",
        "  layers.Dense(90, activation='relu'),\n",
        "  layers.Dense(30)\n",
        "  ])\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13-MxyaiIueX",
        "colab_type": "code",
        "outputId": "d4600e15-2a54-4cbc-9479-081eccc25306",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model_drop_na=get_Model()\n",
        "Adam=tf.train.AdamOptimizer(0.001)\n",
        "#(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
        "\n",
        "file_checkpoint_name='face_model-adam-mse-lr001-dropna.h5'\n",
        "\n",
        "model_drop_na.compile(optimizer=Adam, loss='mean_squared_error', metrics=['acc','mse'])\n",
        "\n",
        "\n",
        "checkpointer = callbacks.ModelCheckpoint(filepath=file_checkpoint_name, verbose=1, save_best_only=True)\n",
        "\n",
        "epochs = 30\n",
        "history=model_drop_na.fit(train_images_clean, train_features_clean,  validation_split=0.2, batch_size=32,epochs=epochs, callbacks=[checkpointer], verbose=1)\n",
        "#history = model_drop_na.fit(train_images_clean, train_features_clean, validation_split=0.2, shuffle=True, epochs=epochs, batch_size=30, callbacks=[checkpointer], verbose=1)\n",
        "\n",
        "#files.download(file_checkpoint_name) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0826 22:17:19.473939 140326085265280 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 1712 samples, validate on 428 samples\n",
            "Epoch 1/30\n",
            "1696/1712 [============================>.] - ETA: 0s - loss: 549.1911 - acc: 0.4251 - mean_squared_error: 549.1909"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0826 22:17:54.466754 140326085265280 hdf5_format.py:110] TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 00001: val_loss improved from inf to 1119.43298, saving model to face_model-adam-mse-lr001-dropna.h5\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1712/1712 [==============================] - 34s 20ms/sample - loss: 544.9757 - acc: 0.4276 - mean_squared_error: 544.9755 - val_loss: 1119.4330 - val_acc: 0.4322 - val_mean_squared_error: 1119.4330\n",
            "Epoch 2/30\n",
            "1696/1712 [============================>.] - ETA: 0s - loss: 93.0681 - acc: 0.7730 - mean_squared_error: 93.0681"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0826 22:18:28.702998 140326085265280 hdf5_format.py:110] TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 00002: val_loss improved from 1119.43298 to 757.78213, saving model to face_model-adam-mse-lr001-dropna.h5\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1712/1712 [==============================] - 34s 20ms/sample - loss: 92.7270 - acc: 0.7734 - mean_squared_error: 92.7270 - val_loss: 757.7821 - val_acc: 0.4322 - val_mean_squared_error: 757.7820\n",
            "Epoch 3/30\n",
            "1696/1712 [============================>.] - ETA: 0s - loss: 72.8246 - acc: 0.7742 - mean_squared_error: 72.8246"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0826 22:19:02.841443 140326085265280 hdf5_format.py:110] TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 00003: val_loss improved from 757.78213 to 585.10687, saving model to face_model-adam-mse-lr001-dropna.h5\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1712/1712 [==============================] - 34s 20ms/sample - loss: 72.9115 - acc: 0.7734 - mean_squared_error: 72.9115 - val_loss: 585.1069 - val_acc: 0.4322 - val_mean_squared_error: 585.1068\n",
            "Epoch 4/30\n",
            "1696/1712 [============================>.] - ETA: 0s - loss: 56.1148 - acc: 0.7718 - mean_squared_error: 56.1148"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0826 22:19:36.951254 140326085265280 hdf5_format.py:110] TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 00004: val_loss improved from 585.10687 to 432.66493, saving model to face_model-adam-mse-lr001-dropna.h5\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1712/1712 [==============================] - 34s 20ms/sample - loss: 55.9938 - acc: 0.7734 - mean_squared_error: 55.9938 - val_loss: 432.6649 - val_acc: 0.4322 - val_mean_squared_error: 432.6649\n",
            "Epoch 5/30\n",
            "1696/1712 [============================>.] - ETA: 0s - loss: 46.6147 - acc: 0.7742 - mean_squared_error: 46.6147"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0826 22:20:10.943839 140326085265280 hdf5_format.py:110] TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 00005: val_loss improved from 432.66493 to 409.56760, saving model to face_model-adam-mse-lr001-dropna.h5\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1712/1712 [==============================] - 34s 20ms/sample - loss: 46.4856 - acc: 0.7734 - mean_squared_error: 46.4856 - val_loss: 409.5676 - val_acc: 0.4322 - val_mean_squared_error: 409.5676\n",
            "Epoch 6/30\n",
            "1696/1712 [============================>.] - ETA: 0s - loss: 39.1031 - acc: 0.7730 - mean_squared_error: 39.1031"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0826 22:20:45.119473 140326085265280 hdf5_format.py:110] TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 00006: val_loss improved from 409.56760 to 139.89610, saving model to face_model-adam-mse-lr001-dropna.h5\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1712/1712 [==============================] - 34s 20ms/sample - loss: 39.0911 - acc: 0.7734 - mean_squared_error: 39.0911 - val_loss: 139.8961 - val_acc: 0.4322 - val_mean_squared_error: 139.8961\n",
            "Epoch 7/30\n",
            "1696/1712 [============================>.] - ETA: 0s - loss: 38.0251 - acc: 0.7742 - mean_squared_error: 38.0251\n",
            "Epoch 00007: val_loss did not improve from 139.89610\n",
            "1712/1712 [==============================] - 34s 20ms/sample - loss: 38.5658 - acc: 0.7734 - mean_squared_error: 38.5658 - val_loss: 166.7467 - val_acc: 0.4322 - val_mean_squared_error: 166.7466\n",
            "Epoch 8/30\n",
            "1696/1712 [============================>.] - ETA: 0s - loss: 51.1243 - acc: 0.7742 - mean_squared_error: 51.1243"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0826 22:21:53.221958 140326085265280 hdf5_format.py:110] TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 00008: val_loss improved from 139.89610 to 139.37819, saving model to face_model-adam-mse-lr001-dropna.h5\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1712/1712 [==============================] - 34s 20ms/sample - loss: 50.8703 - acc: 0.7734 - mean_squared_error: 50.8703 - val_loss: 139.3782 - val_acc: 0.4322 - val_mean_squared_error: 139.3782\n",
            "Epoch 9/30\n",
            "1696/1712 [============================>.] - ETA: 0s - loss: 35.6700 - acc: 0.7724 - mean_squared_error: 35.6700"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0826 22:22:27.197630 140326085265280 hdf5_format.py:110] TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 00009: val_loss improved from 139.37819 to 99.75518, saving model to face_model-adam-mse-lr001-dropna.h5\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1712/1712 [==============================] - 34s 20ms/sample - loss: 35.4830 - acc: 0.7734 - mean_squared_error: 35.4830 - val_loss: 99.7552 - val_acc: 0.4322 - val_mean_squared_error: 99.7552\n",
            "Epoch 10/30\n",
            "1696/1712 [============================>.] - ETA: 0s - loss: 41.1456 - acc: 0.7742 - mean_squared_error: 41.1456"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0826 22:23:01.358391 140326085265280 hdf5_format.py:110] TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 00010: val_loss improved from 99.75518 to 82.33314, saving model to face_model-adam-mse-lr001-dropna.h5\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1712/1712 [==============================] - 34s 20ms/sample - loss: 41.2507 - acc: 0.7734 - mean_squared_error: 41.2507 - val_loss: 82.3331 - val_acc: 0.4322 - val_mean_squared_error: 82.3331\n",
            "Epoch 11/30\n",
            "1696/1712 [============================>.] - ETA: 0s - loss: 32.8504 - acc: 0.7718 - mean_squared_error: 32.8504\n",
            "Epoch 00011: val_loss did not improve from 82.33314\n",
            "1712/1712 [==============================] - 34s 20ms/sample - loss: 32.7733 - acc: 0.7734 - mean_squared_error: 32.7733 - val_loss: 84.1986 - val_acc: 0.4322 - val_mean_squared_error: 84.1986\n",
            "Epoch 12/30\n",
            "1696/1712 [============================>.] - ETA: 0s - loss: 41.7956 - acc: 0.7730 - mean_squared_error: 41.7956"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0826 22:24:09.606859 140326085265280 hdf5_format.py:110] TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 00012: val_loss improved from 82.33314 to 77.51779, saving model to face_model-adam-mse-lr001-dropna.h5\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1712/1712 [==============================] - 34s 20ms/sample - loss: 41.6286 - acc: 0.7734 - mean_squared_error: 41.6286 - val_loss: 77.5178 - val_acc: 0.4322 - val_mean_squared_error: 77.5178\n",
            "Epoch 13/30\n",
            "1696/1712 [============================>.] - ETA: 0s - loss: 27.7127 - acc: 0.7736 - mean_squared_error: 27.7127"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0826 22:24:43.712059 140326085265280 hdf5_format.py:110] TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 00013: val_loss improved from 77.51779 to 75.44741, saving model to face_model-adam-mse-lr001-dropna.h5\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1712/1712 [==============================] - 34s 20ms/sample - loss: 27.7235 - acc: 0.7734 - mean_squared_error: 27.7235 - val_loss: 75.4474 - val_acc: 0.4322 - val_mean_squared_error: 75.4474\n",
            "Epoch 14/30\n",
            "1696/1712 [============================>.] - ETA: 0s - loss: 28.7940 - acc: 0.7736 - mean_squared_error: 28.7940\n",
            "Epoch 00014: val_loss did not improve from 75.44741\n",
            "1712/1712 [==============================] - 34s 20ms/sample - loss: 28.6648 - acc: 0.7734 - mean_squared_error: 28.6648 - val_loss: 150.0161 - val_acc: 0.4322 - val_mean_squared_error: 150.0161\n",
            "Epoch 15/30\n",
            "1696/1712 [============================>.] - ETA: 0s - loss: 61.5448 - acc: 0.7736 - mean_squared_error: 61.5448\n",
            "Epoch 00015: val_loss did not improve from 75.44741\n",
            "1712/1712 [==============================] - 34s 20ms/sample - loss: 61.2227 - acc: 0.7734 - mean_squared_error: 61.2227 - val_loss: 81.6387 - val_acc: 0.4322 - val_mean_squared_error: 81.6387\n",
            "Epoch 16/30\n",
            "1696/1712 [============================>.] - ETA: 0s - loss: 32.9952 - acc: 0.7742 - mean_squared_error: 32.9952\n",
            "Epoch 00016: val_loss did not improve from 75.44741\n",
            "1712/1712 [==============================] - 34s 20ms/sample - loss: 32.8206 - acc: 0.7734 - mean_squared_error: 32.8206 - val_loss: 91.7437 - val_acc: 0.4322 - val_mean_squared_error: 91.7437\n",
            "Epoch 17/30\n",
            "1696/1712 [============================>.] - ETA: 0s - loss: 28.5201 - acc: 0.7742 - mean_squared_error: 28.5201\n",
            "Epoch 00017: val_loss did not improve from 75.44741\n",
            "1712/1712 [==============================] - 34s 20ms/sample - loss: 28.4418 - acc: 0.7734 - mean_squared_error: 28.4418 - val_loss: 81.5674 - val_acc: 0.4322 - val_mean_squared_error: 81.5674\n",
            "Epoch 18/30\n",
            "1696/1712 [============================>.] - ETA: 0s - loss: 43.4161 - acc: 0.7736 - mean_squared_error: 43.4161"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0826 22:27:34.886251 140326085265280 hdf5_format.py:110] TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 00018: val_loss improved from 75.44741 to 72.10359, saving model to face_model-adam-mse-lr001-dropna.h5\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1712/1712 [==============================] - 34s 20ms/sample - loss: 43.4526 - acc: 0.7734 - mean_squared_error: 43.4526 - val_loss: 72.1036 - val_acc: 0.4322 - val_mean_squared_error: 72.1036\n",
            "Epoch 19/30\n",
            "1600/1712 [===========================>..] - ETA: 2s - loss: 28.7535 - acc: 0.7775 - mean_squared_error: 28.7535"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-078b89396c1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mhistory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_drop_na\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images_clean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_features_clean\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpointer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;31m#history = model_drop_na.fit(train_images_clean, train_features_clean, validation_split=0.2, shuffle=True, epochs=epochs, batch_size=30, callbacks=[checkpointer], verbose=1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0mbefore\u001b[0m \u001b[0mdeclaring\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mprediction\u001b[0m \u001b[0mround\u001b[0m \u001b[0mfinished\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0mIgnored\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0mof\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0ma\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m             \u001b[0mdataset\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0ma\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mwill\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m             \u001b[0mrun\u001b[0m \u001b[0muntil\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minput\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mexhausted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m \u001b[0mof\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCallback\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0minstances\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mins\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m             \u001b[0;31m# Do not slice the training phase flag.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m             \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m           \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3290\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3292\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3293\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3294\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZm9D1pLhDJ8",
        "colab_type": "code",
        "outputId": "88059572-a6ba-4f20-e3f8-055aca6474af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "import os\n",
        "import pprint\n",
        "use_tpu = True #@param {type:\"boolean\"}\n",
        "\n",
        "if use_tpu:\n",
        "    assert 'COLAB_TPU_ADDR' in os.environ, 'Missing TPU; did you request a TPU in Notebook Settings?'\n",
        "\n",
        "if 'COLAB_TPU_ADDR' in os.environ:\n",
        "  TF_MASTER = 'grpc://{}'.format(os.environ['COLAB_TPU_ADDR'])\n",
        "else:\n",
        "  TF_MASTER=''\n",
        "\n",
        "with tf.Session(TF_MASTER) as session:\n",
        "  print ('List of devices:')\n",
        "  pprint.pprint(session.list_devices())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "List of devices:\n",
            "[_DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:CPU:0, CPU, -1, 7290481272889922896),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 11969603247550039086),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 10427232135652081834),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 7242172634140884416),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 7395168267477971138),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 1514941088021691226),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 14245311141171946107),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 13014049163277534302),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 7457356830558073233),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 17846141785674529029),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 6168829438145669199)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xx3suHEZgBve",
        "colab_type": "code",
        "outputId": "ccbaba08-6fec-43be-e45f-b1447608cdac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "resolver = tf.contrib.cluster_resolver.TPUClusterResolver(TF_MASTER)\n",
        "tf.contrib.distribute.initialize_tpu_system(resolver)\n",
        "strategy = tf.contrib.distribute.TPUStrategy(resolver)\n",
        "\"Warning: THIS FUNCTION IS DEPRECATED. It will be removed after 2019-02-20. Instructions for updating: Switch to tf.contrib.distribute.TPUStrategy. https://www.tensorflow.org/api_docs/python/tf/contrib/distribute/DistributionStrategy\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-e6e98c97a344>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mresolver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster_resolver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTPUClusterResolver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTF_MASTER\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize_tpu_system\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresolver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTPUStrategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresolver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\"Warning: THIS FUNCTION IS DEPRECATED. It will be removed after 2019-02-20. Instructions for updating: Switch to tf.contrib.distribute.TPUStrategy. https://www.tensorflow.org/api_docs/python/tf/contrib/distribute/DistributionStrategy\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow.contrib.distribute' has no attribute 'initialize_tpu_system'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdZb0gHcgRSN",
        "colab_type": "code",
        "outputId": "48967a85-c483-47d0-fd49-bd908ef1baa0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        }
      },
      "source": [
        "with strategy.scope():\n",
        "  model = get_model()\n",
        "  model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1), \n",
        "                 loss='mean_squared_error', metrics=['acc','mse'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "batch_normalization_2 (Batch (None, 96, 96, 1)         4         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 96, 96, 24)        624       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 48, 48, 24)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 44, 44, 36)        21636     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 (None, 22, 22, 36)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 18, 18, 48)        43248     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling (None, 9, 9, 48)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 7, 7, 64)          27712     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling (None, 3, 3, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 1, 1, 64)          36928     \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_2 ( (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 500)               32500     \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 90)                45090     \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 30)                2730      \n",
            "=================================================================\n",
            "Total params: 210,472\n",
            "Trainable params: 210,470\n",
            "Non-trainable params: 2\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8sRrqYqik4t",
        "colab_type": "code",
        "outputId": "2790c2f5-f1a8-48c4-c6cd-49b41b4475ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "file_checkpoint_name='face_model-adam-TPU-mse-lr001-dropna.h5'\n",
        "\n",
        "\n",
        "img = train_images_clean.astype(np.float32)\n",
        "\n",
        "feats=train_features_clean.astype(np.float32)\n",
        "\n",
        "checkpointer = callbacks.ModelCheckpoint(filepath=file_checkpoint_name, verbose=1, save_best_only=True)\n",
        "\n",
        "epochs = 30\n",
        "history=model.fit(x=img[0:1696],y=feats[0:1696],validation_data=(img[1697:2125],feats[1697:2125]), epochs=epochs, callbacks=[checkpointer], verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "14/14 [==============================] - 6s 426ms/step\n",
            "14/14 [==============================] - 6s 426ms/step\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 18.26732, saving model to face_model-adam-TPU-mse-lr001-dropna.h5\n",
            "53/53 [==============================] - 18s 344ms/step - loss: 6924051316.1941 - acc: 0.5377 - mean_squared_error: 6924050944.0000 - val_loss: 18.2673 - val_acc: 0.4299 - val_mean_squared_error: 19.1209\n",
            "Epoch 2/30\n",
            "14/14 [==============================] - 6s 464ms/step\n",
            "14/14 [==============================] - 6s 464ms/step\n",
            "\n",
            "Epoch 00002: val_loss improved from 18.26732 to 18.17977, saving model to face_model-adam-TPU-mse-lr001-dropna.h5\n",
            "53/53 [==============================] - 11s 205ms/step - loss: 8.7811 - acc: 0.7765 - mean_squared_error: 8.7811 - val_loss: 18.1798 - val_acc: 0.4299 - val_mean_squared_error: 19.0293\n",
            "Epoch 3/30\n",
            "14/14 [==============================] - 8s 537ms/step\n",
            "14/14 [==============================] - 8s 538ms/step\n",
            "\n",
            "Epoch 00003: val_loss improved from 18.17977 to 17.90663, saving model to face_model-adam-TPU-mse-lr001-dropna.h5\n",
            "53/53 [==============================] - 12s 226ms/step - loss: 9.2839 - acc: 0.7765 - mean_squared_error: 9.2839 - val_loss: 17.9066 - val_acc: 0.4299 - val_mean_squared_error: 18.7434\n",
            "Epoch 4/30\n",
            "14/14 [==============================] - 8s 602ms/step\n",
            "14/14 [==============================] - 8s 602ms/step\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 17.90663\n",
            "53/53 [==============================] - 13s 244ms/step - loss: 9.0249 - acc: 0.7765 - mean_squared_error: 9.0249 - val_loss: 19.5526 - val_acc: 0.4299 - val_mean_squared_error: 20.4662\n",
            "Epoch 5/30\n",
            "14/14 [==============================] - 9s 619ms/step\n",
            "14/14 [==============================] - 9s 619ms/step\n",
            "\n",
            "Epoch 00005: val_loss improved from 17.90663 to 16.24592, saving model to face_model-adam-TPU-mse-lr001-dropna.h5\n",
            "53/53 [==============================] - 14s 261ms/step - loss: 9.1053 - acc: 0.7765 - mean_squared_error: 9.1053 - val_loss: 16.2459 - val_acc: 0.4299 - val_mean_squared_error: 17.0051\n",
            "Epoch 6/30\n",
            "14/14 [==============================] - 9s 651ms/step\n",
            "14/14 [==============================] - 9s 651ms/step\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 16.24592\n",
            "53/53 [==============================] - 14s 271ms/step - loss: 8.7849 - acc: 0.7765 - mean_squared_error: 8.7849 - val_loss: 16.3288 - val_acc: 0.4299 - val_mean_squared_error: 17.0919\n",
            "Epoch 7/30\n",
            "14/14 [==============================] - 10s 709ms/step\n",
            "14/14 [==============================] - 10s 709ms/step\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 16.24592\n",
            "53/53 [==============================] - 16s 297ms/step - loss: 8.7512 - acc: 0.7765 - mean_squared_error: 8.7512 - val_loss: 16.3271 - val_acc: 0.4299 - val_mean_squared_error: 17.0900\n",
            "Epoch 8/30\n",
            "14/14 [==============================] - 11s 781ms/step\n",
            "14/14 [==============================] - 11s 781ms/step\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 16.24592\n",
            "53/53 [==============================] - 17s 327ms/step - loss: 9.2001 - acc: 0.7765 - mean_squared_error: 9.2001 - val_loss: 20.5083 - val_acc: 0.4299 - val_mean_squared_error: 21.4666\n",
            "Epoch 9/30\n",
            "14/14 [==============================] - 12s 827ms/step\n",
            "14/14 [==============================] - 12s 827ms/step\n",
            "\n",
            "Epoch 00009: val_loss improved from 16.24592 to 16.10130, saving model to face_model-adam-TPU-mse-lr001-dropna.h5\n",
            "53/53 [==============================] - 18s 338ms/step - loss: 8.7729 - acc: 0.7765 - mean_squared_error: 8.7729 - val_loss: 16.1013 - val_acc: 0.4299 - val_mean_squared_error: 16.8537\n",
            "Epoch 10/30\n",
            "14/14 [==============================] - 13s 895ms/step\n",
            "14/14 [==============================] - 13s 895ms/step\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 16.10130\n",
            "53/53 [==============================] - 19s 364ms/step - loss: 8.8886 - acc: 0.7765 - mean_squared_error: 8.8886 - val_loss: 16.8451 - val_acc: 0.4299 - val_mean_squared_error: 17.6322\n",
            "Epoch 11/30\n",
            "14/14 [==============================] - 13s 923ms/step\n",
            "14/14 [==============================] - 13s 923ms/step\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 16.10130\n",
            "53/53 [==============================] - 20s 382ms/step - loss: 8.8119 - acc: 0.7765 - mean_squared_error: 8.8119 - val_loss: 16.6438 - val_acc: 0.4299 - val_mean_squared_error: 17.4216\n",
            "Epoch 12/30\n",
            "14/14 [==============================] - 14s 1s/step\n",
            "14/14 [==============================] - 14s 1s/step\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 16.10130\n",
            "53/53 [==============================] - 22s 412ms/step - loss: 8.6026 - acc: 0.7765 - mean_squared_error: 8.6026 - val_loss: 16.1616 - val_acc: 0.4299 - val_mean_squared_error: 16.9168\n",
            "Epoch 13/30\n",
            "14/14 [==============================] - 14s 1s/step\n",
            "14/14 [==============================] - 14s 1s/step\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 16.10130\n",
            "53/53 [==============================] - 22s 418ms/step - loss: 8.8177 - acc: 0.7765 - mean_squared_error: 8.8177 - val_loss: 16.4863 - val_acc: 0.4299 - val_mean_squared_error: 17.2567\n",
            "Epoch 14/30\n",
            "14/14 [==============================] - 16s 1s/step\n",
            "14/14 [==============================] - 16s 1s/step\n",
            "\n",
            "Epoch 00014: val_loss improved from 16.10130 to 15.92184, saving model to face_model-adam-TPU-mse-lr001-dropna.h5\n",
            "53/53 [==============================] - 24s 460ms/step - loss: 8.6529 - acc: 0.7765 - mean_squared_error: 8.6529 - val_loss: 15.9218 - val_acc: 0.4299 - val_mean_squared_error: 16.6658\n",
            "Epoch 15/30\n",
            "14/14 [==============================] - 16s 1s/step\n",
            "14/14 [==============================] - 16s 1s/step\n",
            "\n",
            "Epoch 00015: val_loss improved from 15.92184 to 15.91105, saving model to face_model-adam-TPU-mse-lr001-dropna.h5\n",
            "53/53 [==============================] - 25s 479ms/step - loss: 8.9836 - acc: 0.7765 - mean_squared_error: 8.9836 - val_loss: 15.9110 - val_acc: 0.4299 - val_mean_squared_error: 16.6546\n",
            "Epoch 16/30\n",
            "14/14 [==============================] - 18s 1s/step\n",
            "14/14 [==============================] - 18s 1s/step\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 15.91105\n",
            "53/53 [==============================] - 27s 513ms/step - loss: 8.6227 - acc: 0.7765 - mean_squared_error: 8.6227 - val_loss: 16.2624 - val_acc: 0.4299 - val_mean_squared_error: 17.0223\n",
            "Epoch 17/30\n",
            "14/14 [==============================] - 18s 1s/step\n",
            "14/14 [==============================] - 18s 1s/step\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 15.91105\n",
            "53/53 [==============================] - 29s 542ms/step - loss: 8.5462 - acc: 0.7765 - mean_squared_error: 8.5462 - val_loss: 16.3047 - val_acc: 0.4299 - val_mean_squared_error: 17.0666\n",
            "Epoch 18/30\n",
            "14/14 [==============================] - 20s 1s/step\n",
            "14/14 [==============================] - 20s 1s/step\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 15.91105\n",
            "53/53 [==============================] - 30s 567ms/step - loss: 8.6817 - acc: 0.7765 - mean_squared_error: 8.6817 - val_loss: 16.2372 - val_acc: 0.4299 - val_mean_squared_error: 16.9959\n",
            "Epoch 19/30\n",
            "14/14 [==============================] - 20s 1s/step\n",
            "14/14 [==============================] - 20s 1s/step\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 15.91105\n",
            "53/53 [==============================] - 30s 567ms/step - loss: 8.8310 - acc: 0.7765 - mean_squared_error: 8.8310 - val_loss: 16.3490 - val_acc: 0.4299 - val_mean_squared_error: 17.1130\n",
            "Epoch 20/30\n",
            "14/14 [==============================] - 21s 2s/step\n",
            "14/14 [==============================] - 21s 2s/step\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 15.91105\n",
            "53/53 [==============================] - 32s 603ms/step - loss: 8.6780 - acc: 0.7765 - mean_squared_error: 8.6780 - val_loss: 16.2523 - val_acc: 0.4299 - val_mean_squared_error: 17.0117\n",
            "Epoch 21/30\n",
            "14/14 [==============================] - 23s 2s/step\n",
            "14/14 [==============================] - 23s 2s/step\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 15.91105\n",
            "53/53 [==============================] - 34s 646ms/step - loss: 8.6552 - acc: 0.7765 - mean_squared_error: 8.6552 - val_loss: 16.1292 - val_acc: 0.4299 - val_mean_squared_error: 16.8829\n",
            "Epoch 22/30\n",
            "14/14 [==============================] - 23s 2s/step\n",
            "14/14 [==============================] - 23s 2s/step\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 15.91105\n",
            "53/53 [==============================] - 36s 685ms/step - loss: 8.7338 - acc: 0.7765 - mean_squared_error: 8.7338 - val_loss: 16.5651 - val_acc: 0.4299 - val_mean_squared_error: 17.3392\n",
            "Epoch 23/30\n",
            "14/14 [==============================] - 26s 2s/step\n",
            "14/14 [==============================] - 26s 2s/step\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 15.91105\n",
            "53/53 [==============================] - 39s 741ms/step - loss: 8.5513 - acc: 0.7765 - mean_squared_error: 8.5513 - val_loss: 17.3978 - val_acc: 0.4299 - val_mean_squared_error: 18.2108\n",
            "Epoch 24/30\n",
            "14/14 [==============================] - 27s 2s/step\n",
            "14/14 [==============================] - 27s 2s/step\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 15.91105\n",
            "53/53 [==============================] - 40s 749ms/step - loss: 8.7820 - acc: 0.7765 - mean_squared_error: 8.7820 - val_loss: 20.2285 - val_acc: 0.4299 - val_mean_squared_error: 21.1737\n",
            "Epoch 25/30\n",
            "14/14 [==============================] - 27s 2s/step\n",
            "14/14 [==============================] - 27s 2s/step\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 15.91105\n",
            "53/53 [==============================] - 41s 777ms/step - loss: 8.7175 - acc: 0.7765 - mean_squared_error: 8.7175 - val_loss: 16.2509 - val_acc: 0.4299 - val_mean_squared_error: 17.0103\n",
            "Epoch 26/30\n",
            "14/14 [==============================] - 28s 2s/step\n",
            "14/14 [==============================] - 28s 2s/step\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 15.91105\n",
            "53/53 [==============================] - 43s 807ms/step - loss: 8.6693 - acc: 0.7765 - mean_squared_error: 8.6693 - val_loss: 16.4468 - val_acc: 0.4299 - val_mean_squared_error: 17.2153\n",
            "Epoch 27/30\n",
            "14/14 [==============================] - 30s 2s/step\n",
            "14/14 [==============================] - 30s 2s/step\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 15.91105\n",
            "53/53 [==============================] - 45s 854ms/step - loss: 8.5806 - acc: 0.7765 - mean_squared_error: 8.5806 - val_loss: 16.2420 - val_acc: 0.4299 - val_mean_squared_error: 17.0010\n",
            "Epoch 28/30\n",
            "14/14 [==============================] - 31s 2s/step\n",
            "14/14 [==============================] - 31s 2s/step\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 15.91105\n",
            "53/53 [==============================] - 46s 871ms/step - loss: 8.6071 - acc: 0.7765 - mean_squared_error: 8.6071 - val_loss: 17.2832 - val_acc: 0.4299 - val_mean_squared_error: 18.0909\n",
            "Epoch 29/30\n",
            "14/14 [==============================] - 31s 2s/step\n",
            "14/14 [==============================] - 31s 2s/step\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 15.91105\n",
            "53/53 [==============================] - 48s 902ms/step - loss: 8.6136 - acc: 0.7765 - mean_squared_error: 8.6136 - val_loss: 16.1895 - val_acc: 0.4299 - val_mean_squared_error: 16.9460\n",
            "Epoch 30/30\n",
            "14/14 [==============================] - 33s 2s/step\n",
            "14/14 [==============================] - 33s 2s/step\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 15.91105\n",
            "53/53 [==============================] - 50s 949ms/step - loss: 8.8208 - acc: 0.7765 - mean_squared_error: 8.8208 - val_loss: 16.8492 - val_acc: 0.4299 - val_mean_squared_error: 17.6366\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o32YCiPHjYzj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(train_images_clean.shape); print(train_features_clean.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4_eS1WbmbPG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "#time.sleep(10)\n",
        "files.download(file_checkpoint_name) \n",
        "# evaluate the model\n",
        "#_, train_mse = model.evaluate(train_images_cnn, train_features_cnn, verbose=0)\n",
        "#_, test_mse = model.evaluate(train_images_dirty, train_features_dirty, verbose=0)\n",
        "#print('Train: %.3f, Test: %.3f' % (train_mse, test_mse))\n",
        "# plot loss during training\n",
        "\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7zGMSROB4ZL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4nLEprP-iGC",
        "colab_type": "code",
        "outputId": "909fc019-51e9-4e90-d208-7e0a71795be5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "\n",
        "import os\n",
        "def train_input_fn(x_train,y_train,batch_size=850):\n",
        "    # Convert the inputs to a Dataset.\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((x_train,y_train))\n",
        "# Shuffle, repeat, and batch the examples.\n",
        "    dataset = dataset.cache()\n",
        "    dataset = dataset.shuffle(850, reshuffle_each_iteration=True)\n",
        "    dataset = dataset.repeat()\n",
        "    dataset = dataset.batch(batch_size, drop_remainder=True)\n",
        "# Return the dataset.\n",
        "    return dataset\n",
        "\n",
        "try:\n",
        " device_name = os.environ['COLAB_TPU_ADDR']\n",
        " TPU_ADDRESS = 'grpc://' + device_name\n",
        " print('Found TPU at: {}'.format(TPU_ADDRESS))\n",
        "except KeyError:\n",
        " print('TPU not found')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found TPU at: grpc://10.113.166.170:8470\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_AW09r6ZBGX",
        "colab_type": "code",
        "outputId": "288abf3e-70c1-4a5b-a478-0afa73cd5715",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "import pprint\n",
        "use_tpu = True #@param {type:\"boolean\"}\n",
        "if use_tpu:\n",
        "    assert 'COLAB_TPU_ADDR' in os.environ, 'Missing TPU; did you request a TPU in Notebook Settings?'\n",
        "\n",
        "if 'COLAB_TPU_ADDR' in os.environ:\n",
        "  TF_MASTER = 'grpc://{}'.format(os.environ['COLAB_TPU_ADDR'])\n",
        "else:\n",
        "  TF_MASTER=''\n",
        "\n",
        "with tf.Session(TF_MASTER) as session:\n",
        "  print ('List of devices:')\n",
        "  pprint.pprint(session.list_devices())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "List of devices:\n",
            "[_DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:CPU:0, CPU, -1, 7290481272889922896),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 11969603247550039086),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 10427232135652081834),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 7242172634140884416),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 7395168267477971138),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 1514941088021691226),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 14245311141171946107),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 13014049163277534302),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 7457356830558073233),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 17846141785674529029),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 6168829438145669199)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfy_GdrcZnbF",
        "colab_type": "code",
        "outputId": "d4b51a69-903a-4313-fabd-736da458d652",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        }
      },
      "source": [
        "\"Warning: THIS FUNCTION IS DEPRECATED. It will be removed after 2019-02-20. Instructions for updating: Switch to tf.contrib.distribute.TPUStrategy. https://www.tensorflow.org/api_docs/python/tf/contrib/distribute/DistributionStrategy\"\n",
        "TPU_WORKER = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "tf.logging.set_verbosity(tf.logging.INFO)\n",
        "model_drop_na=get_Model()\n",
        "Adam=tf.train.AdamOptimizer(0.001)\n",
        "#(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
        "\n",
        "file_checkpoint_name='face.h5'\n",
        "strategy=tf.contrib.tpu.TPUDistributionStrategy(tf.contrib.cluster_resolver.TPUClusterResolver(tpu=TPU_WORKER))\n",
        "model_drop_na.compile(optimizer=Adam, loss='mean_squared_error', metrics=['acc','mse'])\n",
        "resnet_model = tf.contrib.tpu.keras_to_tpu_model(model_drop_na,strategy=strategy)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "\n",
            "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.113.166.170:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 7290481272889922896)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 11969603247550039086)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 10427232135652081834)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 7242172634140884416)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 7395168267477971138)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 1514941088021691226)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 14245311141171946107)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 13014049163277534302)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 7457356830558073233)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 17846141785674529029)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 6168829438145669199)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/losses_utils.py:170: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K12-ZzzZCYyz",
        "colab_type": "code",
        "outputId": "c97edaaa-fc9d-4112-f14d-d5e94ecbca3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        }
      },
      "source": [
        "from tensorflow.contrib.tpu.python.tpu import keras_support \n",
        "\n",
        "resolver = tf.contrib.cluster_resolver.TPUClusterResolver(tpu=TPU_WORKER)\n",
        "strategy = keras_support.TPUDistributionStrategy(resolver)\n",
        "keras_model = keras_support.tpu_model(get_Model(), strategy)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.113.166.170:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 7290481272889922896)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 11969603247550039086)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 10427232135652081834)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 7242172634140884416)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 7395168267477971138)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 1514941088021691226)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 14245311141171946107)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 13014049163277534302)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 7457356830558073233)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 17846141785674529029)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 6168829438145669199)\n",
            "WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b13NsuKVWCzT",
        "colab_type": "code",
        "outputId": "f235dc23-111a-4265-f2e2-5516208db5a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "img = train_images_clean.astype(np.float32)\n",
        "\n",
        "feats=train_features_clean.astype(np.float32)\n",
        "\n",
        "checkpointer = callbacks.ModelCheckpoint(filepath=file_checkpoint_name, verbose=1, save_best_only=True)\n",
        "keras_model.compile(loss='mean_squared_error', metrics=['acc','mse'], optimizer=tf.train.AdamOptimizer(0.1))\n",
        "tpu_model = tf.contrib.tpu.keras_to_tpu_model(keras_model,strategy=strategy)\n",
        "\n",
        "epochs = 30\n",
        "#history=tpu_model.fit(x=img[0:1696],y=feats[0:1696],validation_data=(img[1697:2125],feats[1697:2125]), epochs=epochs, callbacks=[checkpointer], verbose=1)\n",
        "history=tpu_model.fit(train_images_clean, train_features_clean,  validation_split=0.2, batch_size=700, epochs=epochs, callbacks=[checkpointer], verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.\n",
            "Train on 2140 samples, validate on 428 samples\n",
            "Epoch 1/30\n",
            "INFO:tensorflow:New input shapes; (re-)compiling: mode=train (# of cores 8), [TensorSpec(shape=(87,), dtype=tf.int32, name='core_id_80'), TensorSpec(shape=(87, 96, 96, 1), dtype=tf.float32, name='input_5_20'), TensorSpec(shape=(87, 30), dtype=tf.float32, name='dense_14_target_40')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input_5\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 17.451564073562622 secs\n",
            "INFO:tensorflow:Setting weights on TPU model.\n",
            "1400/2140 [==================>...........] - ETA: 16s - loss: 86317916252800288.0000 - acc: 870.9141 - mean_squared_error: 43158958126399488.0000INFO:tensorflow:New input shapes; (re-)compiling: mode=train (# of cores 8), [TensorSpec(shape=(5,), dtype=tf.int32, name='core_id_80'), TensorSpec(shape=(5, 96, 96, 1), dtype=tf.float32, name='input_5_20'), TensorSpec(shape=(5, 30), dtype=tf.float32, name='dense_14_target_40')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input_5\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 15.254433155059814 secs\n",
            "2100/2140 [============================>.] - ETA: 1s - loss: 57545277510384656.0000 - acc: 34527164783132672.0000 - mean_squared_error: 28772636603449344.0000INFO:tensorflow:New input shapes; (re-)compiling: mode=eval (# of cores 8), [TensorSpec(shape=(53,), dtype=tf.int32, name='core_id_90'), TensorSpec(shape=(53, 96, 96, 1), dtype=tf.float32, name='input_5_20'), TensorSpec(shape=(53, 30), dtype=tf.float32, name='dense_14_target_40')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input_5\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 12.7367103099823 secs\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 2678.92334, saving model to face.h5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "2140/2140 [==============================] - 96s 45ms/sample - loss: 56469664846639192.0000 - acc: 28499652777082880.0000 - mean_squared_error: 28231799289151488.0000 - val_loss: 2678.9233 - val_acc: 0.0000e+00 - val_mean_squared_error: 1339.4617\n",
            "Epoch 2/30\n",
            "2100/2140 [============================>.] - ETA: 0s - loss: 2628.8718 - acc: 1052.9553 - mean_squared_error: 1314.4359\n",
            "Epoch 00002: val_loss improved from 2678.92334 to 2652.08618, saving model to face.h5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "2140/2140 [==============================] - 11s 5ms/sample - loss: 2628.8016 - acc: 1301.9650 - mean_squared_error: 1314.4006 - val_loss: 2652.0862 - val_acc: 0.0000e+00 - val_mean_squared_error: 1326.0431\n",
            "Epoch 3/30\n",
            "2100/2140 [============================>.] - ETA: 0s - loss: 2559.0449 - acc: 1033.5015 - mean_squared_error: 1279.5225\n",
            "Epoch 00003: val_loss improved from 2652.08618 to 2357.81470, saving model to face.h5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "2140/2140 [==============================] - 11s 5ms/sample - loss: 2556.9223 - acc: 1267.3828 - mean_squared_error: 1278.4553 - val_loss: 2357.8147 - val_acc: 0.0000e+00 - val_mean_squared_error: 1178.9073\n",
            "Epoch 4/30\n",
            "2100/2140 [============================>.] - ETA: 0s - loss: 2138.0483 - acc: 891.5234 - mean_squared_error: 1069.0242\n",
            "Epoch 00004: val_loss improved from 2357.81470 to 1473.14124, saving model to face.h5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "2140/2140 [==============================] - 11s 5ms/sample - loss: 2130.6147 - acc: 1058.8816 - mean_squared_error: 1065.2865 - val_loss: 1473.1412 - val_acc: 0.0000e+00 - val_mean_squared_error: 736.5706\n",
            "Epoch 5/30\n",
            "2100/2140 [============================>.] - ETA: 0s - loss: 1129.5205 - acc: 513.0234 - mean_squared_error: 564.7603\n",
            "Epoch 00005: val_loss improved from 1473.14124 to 395.15656, saving model to face.h5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "2140/2140 [==============================] - 11s 5ms/sample - loss: 1118.8690 - acc: 559.4020 - mean_squared_error: 559.4045 - val_loss: 395.1566 - val_acc: 0.0000e+00 - val_mean_squared_error: 197.5783\n",
            "Epoch 6/30\n",
            "2100/2140 [============================>.] - ETA: 0s - loss: 368.6521 - acc: 143.8811 - mean_squared_error: 184.3260\n",
            "Epoch 00006: val_loss improved from 395.15656 to 347.87735, saving model to face.h5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "2140/2140 [==============================] - 11s 5ms/sample - loss: 369.4669 - acc: 182.5772 - mean_squared_error: 184.7358 - val_loss: 347.8773 - val_acc: 0.0000e+00 - val_mean_squared_error: 173.9387\n",
            "Epoch 7/30\n",
            "2100/2140 [============================>.] - ETA: 0s - loss: 225.3034 - acc: 116.4605 - mean_squared_error: 112.6517\n",
            "Epoch 00007: val_loss improved from 347.87735 to 61.61339, saving model to face.h5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "2140/2140 [==============================] - 11s 5ms/sample - loss: 221.6586 - acc: 111.5829 - mean_squared_error: 110.8191 - val_loss: 61.6134 - val_acc: 0.0519 - val_mean_squared_error: 30.8326\n",
            "Epoch 8/30\n",
            "2100/2140 [============================>.] - ETA: 0s - loss: 113.8732 - acc: 34.7537 - mean_squared_error: 57.0535\n",
            "Epoch 00008: val_loss did not improve from 61.61339\n",
            "2140/2140 [==============================] - 6s 3ms/sample - loss: 115.1048 - acc: 56.5195 - mean_squared_error: 57.6778 - val_loss: 166.3257 - val_acc: 0.4292 - val_mean_squared_error: 83.3774\n",
            "Epoch 9/30\n",
            "2100/2140 [============================>.] - ETA: 0s - loss: 124.9979 - acc: 55.8014 - mean_squared_error: 62.8519\n",
            "Epoch 00009: val_loss did not improve from 61.61339\n",
            "2140/2140 [==============================] - 6s 3ms/sample - loss: 124.4437 - acc: 62.2620 - mean_squared_error: 62.5729 - val_loss: 98.7908 - val_acc: 0.4292 - val_mean_squared_error: 49.6100\n",
            "Epoch 10/30\n",
            "2100/2140 [============================>.] - ETA: 0s - loss: 87.5757 - acc: 38.3338 - mean_squared_error: 44.1403\n",
            "Epoch 00010: val_loss improved from 61.61339 to 31.77779, saving model to face.h5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "2140/2140 [==============================] - 11s 5ms/sample - loss: 86.8309 - acc: 43.7291 - mean_squared_error: 43.7667 - val_loss: 31.7778 - val_acc: 0.4292 - val_mean_squared_error: 16.1035\n",
            "Epoch 11/30\n",
            "2100/2140 [============================>.] - ETA: 0s - loss: 23.4104 - acc: 9.8194 - mean_squared_error: 12.0589\n",
            "Epoch 00011: val_loss did not improve from 31.77779\n",
            "2140/2140 [==============================] - 6s 3ms/sample - loss: 23.5717 - acc: 11.9509 - mean_squared_error: 12.1397 - val_loss: 50.0100 - val_acc: 0.4292 - val_mean_squared_error: 25.2196\n",
            "Epoch 12/30\n",
            "2100/2140 [============================>.] - ETA: 0s - loss: 38.0138 - acc: 15.9275 - mean_squared_error: 19.3586\n",
            "Epoch 00012: val_loss did not improve from 31.77779\n",
            "2140/2140 [==============================] - 6s 3ms/sample - loss: 37.8338 - acc: 19.1826 - mean_squared_error: 19.2691 - val_loss: 39.1498 - val_acc: 0.4292 - val_mean_squared_error: 19.7895\n",
            "Epoch 13/30\n",
            "2100/2140 [============================>.] - ETA: 0s - loss: 29.6173 - acc: 12.3003 - mean_squared_error: 15.1609\n",
            "Epoch 00013: val_loss did not improve from 31.77779\n",
            "2140/2140 [==============================] - 6s 3ms/sample - loss: 29.6235 - acc: 15.0240 - mean_squared_error: 15.1642 - val_loss: 34.7557 - val_acc: 0.4292 - val_mean_squared_error: 17.5925\n",
            "Epoch 14/30\n",
            "2100/2140 [============================>.] - ETA: 0s - loss: 24.1925 - acc: 11.1515 - mean_squared_error: 12.4490\n",
            "Epoch 00014: val_loss improved from 31.77779 to 21.16985, saving model to face.h5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "2140/2140 [==============================] - 11s 5ms/sample - loss: 24.0853 - acc: 12.3375 - mean_squared_error: 12.3950 - val_loss: 21.1698 - val_acc: 0.4292 - val_mean_squared_error: 10.7995\n",
            "Epoch 15/30\n",
            "2100/2140 [============================>.] - ETA: 0s - loss: 14.9501 - acc: 6.3151 - mean_squared_error: 7.8292\n",
            "Epoch 00015: val_loss did not improve from 21.16985\n",
            "2140/2140 [==============================] - 6s 3ms/sample - loss: 14.9657 - acc: 7.7609 - mean_squared_error: 7.8363 - val_loss: 22.5149 - val_acc: 0.4292 - val_mean_squared_error: 11.4721\n",
            "Epoch 16/30\n",
            "2100/2140 [============================>.] - ETA: 0s - loss: 14.7888 - acc: 6.4924 - mean_squared_error: 7.7467\n",
            "Epoch 00016: val_loss improved from 21.16985 to 18.50562, saving model to face.h5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "2140/2140 [==============================] - 11s 5ms/sample - loss: 14.7437 - acc: 7.6800 - mean_squared_error: 7.7242 - val_loss: 18.5056 - val_acc: 0.4292 - val_mean_squared_error: 9.4674\n",
            "Epoch 17/30\n",
            "2100/2140 [============================>.] - ETA: 0s - loss: 14.5957 - acc: 6.2232 - mean_squared_error: 7.6496\n",
            "Epoch 00017: val_loss improved from 18.50562 to 17.03944, saving model to face.h5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "2140/2140 [==============================] - 11s 5ms/sample - loss: 14.5368 - acc: 7.5839 - mean_squared_error: 7.6202 - val_loss: 17.0394 - val_acc: 0.4292 - val_mean_squared_error: 8.7343\n",
            "Epoch 18/30\n",
            "2100/2140 [============================>.] - ETA: 0s - loss: 11.7798 - acc: 5.2572 - mean_squared_error: 6.2429\n",
            "Epoch 00018: val_loss did not improve from 17.03944\n",
            "2140/2140 [==============================] - 6s 3ms/sample - loss: 11.8270 - acc: 6.1898 - mean_squared_error: 6.2661 - val_loss: 18.0589 - val_acc: 0.4292 - val_mean_squared_error: 9.2441\n",
            "Epoch 19/30\n",
            "2100/2140 [============================>.] - ETA: 0s - loss: 11.5347 - acc: 5.0498 - mean_squared_error: 6.1210\n",
            "Epoch 00019: val_loss did not improve from 17.03944\n",
            "2140/2140 [==============================] - 6s 3ms/sample - loss: 11.5438 - acc: 6.0691 - mean_squared_error: 6.1251 - val_loss: 17.4278 - val_acc: 0.4292 - val_mean_squared_error: 8.9285\n",
            "Epoch 20/30\n",
            "2100/2140 [============================>.] - ETA: 0s - loss: 11.2799 - acc: 4.7962 - mean_squared_error: 5.9939\n",
            "Epoch 00020: val_loss did not improve from 17.03944\n",
            "2140/2140 [==============================] - 6s 3ms/sample - loss: 11.2942 - acc: 5.9434 - mean_squared_error: 6.0008 - val_loss: 17.5530 - val_acc: 0.4292 - val_mean_squared_error: 8.9911\n",
            "Epoch 21/30\n",
            "2100/2140 [============================>.] - ETA: 0s - loss: 10.7749 - acc: 4.7691 - mean_squared_error: 5.7421\n",
            "Epoch 00021: val_loss did not improve from 17.03944\n",
            "2140/2140 [==============================] - 6s 3ms/sample - loss: 10.7765 - acc: 5.6921 - mean_squared_error: 5.7407 - val_loss: 18.1694 - val_acc: 0.4292 - val_mean_squared_error: 9.2993\n",
            "Epoch 22/30\n",
            "2100/2140 [============================>.] - ETA: 0s - loss: 10.6991 - acc: 4.7827 - mean_squared_error: 5.7027\n",
            "Epoch 00022: val_loss improved from 17.03944 to 16.69404, saving model to face.h5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "2140/2140 [==============================] - 11s 5ms/sample - loss: 10.6757 - acc: 5.6550 - mean_squared_error: 5.6907 - val_loss: 16.6940 - val_acc: 0.4292 - val_mean_squared_error: 8.5616\n",
            "Epoch 23/30\n",
            "2100/2140 [============================>.] - ETA: 0s - loss: 10.4583 - acc: 4.5888 - mean_squared_error: 5.5814\n",
            "Epoch 00023: val_loss improved from 16.69404 to 16.41477, saving model to face.h5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "2140/2140 [==============================] - 11s 5ms/sample - loss: 10.4663 - acc: 5.5353 - mean_squared_error: 5.5856 - val_loss: 16.4148 - val_acc: 0.4292 - val_mean_squared_error: 8.4220\n",
            "Epoch 24/30\n",
            "2100/2140 [============================>.] - ETA: 0s - loss: 10.4311 - acc: 4.5129 - mean_squared_error: 5.5695\n",
            "Epoch 00024: val_loss did not improve from 16.41477\n",
            "2140/2140 [==============================] - 6s 3ms/sample - loss: 10.4079 - acc: 5.5226 - mean_squared_error: 5.5570 - val_loss: 16.5517 - val_acc: 0.4292 - val_mean_squared_error: 8.4905\n",
            "Epoch 25/30\n",
            "2100/2140 [============================>.] - ETA: 0s - loss: 10.2505 - acc: 4.6153 - mean_squared_error: 5.4782\n",
            "Epoch 00025: val_loss improved from 16.41477 to 16.36789, saving model to face.h5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "2140/2140 [==============================] - 11s 5ms/sample - loss: 10.2210 - acc: 5.4329 - mean_squared_error: 5.4633 - val_loss: 16.3679 - val_acc: 0.4292 - val_mean_squared_error: 8.3986\n",
            "Epoch 26/30\n",
            "2100/2140 [============================>.] - ETA: 0s - loss: 10.2933 - acc: 4.4002 - mean_squared_error: 5.4986\n",
            "Epoch 00026: val_loss did not improve from 16.36789\n",
            "2140/2140 [==============================] - 6s 3ms/sample - loss: 10.2553 - acc: 5.4541 - mean_squared_error: 5.4804 - val_loss: 16.4047 - val_acc: 0.4292 - val_mean_squared_error: 8.4170\n",
            "Epoch 27/30\n",
            "2100/2140 [============================>.] - ETA: 0s - loss: 10.2218 - acc: 4.4768 - mean_squared_error: 5.4638\n",
            "Epoch 00027: val_loss did not improve from 16.36789\n",
            "2140/2140 [==============================] - 6s 3ms/sample - loss: 10.2247 - acc: 5.4184 - mean_squared_error: 5.4650 - val_loss: 16.6453 - val_acc: 0.4292 - val_mean_squared_error: 8.5373\n",
            "Epoch 28/30\n",
            "2100/2140 [============================>.] - ETA: 0s - loss: 10.2066 - acc: 4.5355 - mean_squared_error: 5.4565\n",
            "Epoch 00028: val_loss did not improve from 16.36789\n",
            "2140/2140 [==============================] - 6s 3ms/sample - loss: 10.1761 - acc: 5.4109 - mean_squared_error: 5.4406 - val_loss: 17.3796 - val_acc: 0.4292 - val_mean_squared_error: 8.9044\n",
            "Epoch 29/30\n",
            "2100/2140 [============================>.] - ETA: 0s - loss: 10.3746 - acc: 4.6207 - mean_squared_error: 5.5388\n",
            "Epoch 00029: val_loss improved from 16.36789 to 16.33819, saving model to face.h5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "2140/2140 [==============================] - 11s 5ms/sample - loss: 10.3717 - acc: 5.4939 - mean_squared_error: 5.5383 - val_loss: 16.3382 - val_acc: 0.4292 - val_mean_squared_error: 8.3837\n",
            "Epoch 30/30\n",
            "2100/2140 [============================>.] - ETA: 0s - loss: 10.2913 - acc: 4.5720 - mean_squared_error: 5.4979\n",
            "Epoch 00030: val_loss improved from 16.33819 to 16.25769, saving model to face.h5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "2140/2140 [==============================] - 11s 5ms/sample - loss: 10.2925 - acc: 5.4524 - mean_squared_error: 5.4985 - val_loss: 16.2577 - val_acc: 0.4292 - val_mean_squared_error: 8.3435\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "To1jQCYqZKUP",
        "colab_type": "code",
        "outputId": "553adce2-68c3-4bac-f9f9-d7a781023758",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model_drop_na=get_Model()\n",
        "Adam=tf.train.AdamOptimizer(0.1)\n",
        "\n",
        "\n",
        "file_checkpoint_name='face.h5'\n",
        "strategy=tf.contrib.tpu.TPUDistributionStrategy(tf.contrib.cluster_resolver.TPUClusterResolver(tpu=TPU_WORKER))\n",
        "model_drop_na.compile(optimizer=Adam, loss='mean_squared_error', metrics=['acc','mse'])\n",
        "resnet_model = tf.contrib.tpu.keras_to_tpu_model(model_drop_na,strategy=strategy)\n",
        "history=resnet_model.fit(train_images_clean, train_features_clean,  validation_split=0.2, batch_size=700, epochs=epochs, callbacks=[checkpointer], verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.113.166.170:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 7290481272889922896)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 11969603247550039086)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 10427232135652081834)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 7242172634140884416)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 7395168267477971138)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 1514941088021691226)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 14245311141171946107)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 13014049163277534302)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 7457356830558073233)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 17846141785674529029)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 6168829438145669199)\n",
            "WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.\n",
            "Train on 2140 samples, validate on 428 samples\n",
            "Epoch 1/30\n",
            "INFO:tensorflow:New input shapes; (re-)compiling: mode=train (# of cores 8), [TensorSpec(shape=(87,), dtype=tf.int32, name='core_id_40'), TensorSpec(shape=(87, 96, 96, 1), dtype=tf.float32, name='input_3_10'), TensorSpec(shape=(87, 30), dtype=tf.float32, name='dense_8_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input_3\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 12.850225687026978 secs\n",
            "INFO:tensorflow:Setting weights on TPU model.\n",
            "1400/2140 [==================>...........] - ETA: 12s - loss: 483511921941677312.0000 - acc: 871.4258 - mean_squared_error: 241755960970838016.0000INFO:tensorflow:New input shapes; (re-)compiling: mode=train (# of cores 8), [TensorSpec(shape=(5,), dtype=tf.int32, name='core_id_40'), TensorSpec(shape=(5, 96, 96, 1), dtype=tf.float32, name='input_3_10'), TensorSpec(shape=(5, 30), dtype=tf.float32, name='dense_8_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input_3\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 10.342171430587769 secs\n",
            "2100/2140 [============================>.] - ETA: 0s - loss: 322341281365347072.0000 - acc: 193404765340696576.0000 - mean_squared_error: 161170640647225344.0000INFO:tensorflow:New input shapes; (re-)compiling: mode=eval (# of cores 8), [TensorSpec(shape=(53,), dtype=tf.int32, name='core_id_50'), TensorSpec(shape=(53, 96, 96, 1), dtype=tf.float32, name='input_3_10'), TensorSpec(shape=(53, 30), dtype=tf.float32, name='dense_8_target_30')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input_3\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 7.79414176940918 secs\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 1084.86019\n",
            "2140/2140 [==============================] - 58s 27ms/sample - loss: 316316210685621056.0000 - acc: 159641512030765056.0000 - mean_squared_error: 158141125335449600.0000 - val_loss: 2681.1992 - val_acc: 0.0519 - val_mean_squared_error: 1340.6256\n",
            "Epoch 2/30\n",
            "2100/2140 [============================>.] - ETA: 0s - loss: 2599.5056 - acc: 1048.6023 - mean_squared_error: 1299.7539\n",
            "Epoch 00002: val_loss did not improve from 1084.86019\n",
            "2140/2140 [==============================] - 6s 3ms/sample - loss: 2596.1367 - acc: 1287.4224 - mean_squared_error: 1298.0601 - val_loss: 2264.8799 - val_acc: 0.0000e+00 - val_mean_squared_error: 1132.4399\n",
            "Epoch 3/30\n",
            "2100/2140 [============================>.] - ETA: 0s - loss: 1814.5414 - acc: 815.9874 - mean_squared_error: 907.2707 \n",
            "Epoch 00003: val_loss improved from 1084.86019 to 349.18625, saving model to face.h5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "2140/2140 [==============================] - 15s 7ms/sample - loss: 1795.3956 - acc: 898.6628 - mean_squared_error: 897.6439 - val_loss: 349.1862 - val_acc: 0.0000e+00 - val_mean_squared_error: 174.5931\n",
            "Epoch 4/30\n",
            "2100/2140 [============================>.] - ETA: 0s - loss: 527.1156 - acc: 164.4006 - mean_squared_error: 263.5599\n",
            "Epoch 00004: val_loss improved from 349.18625 to 186.24956, saving model to face.h5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "2140/2140 [==============================] - 9s 4ms/sample - loss: 527.4244 - acc: 261.0594 - mean_squared_error: 263.7152 - val_loss: 186.2496 - val_acc: 0.4292 - val_mean_squared_error: 93.3394\n",
            "Epoch 5/30\n",
            "2100/2140 [============================>.] - ETA: 0s - loss: 85.6992 - acc: 43.3475 - mean_squared_error: 43.2019 \n",
            "Epoch 00005: val_loss did not improve from 186.24956\n",
            "2140/2140 [==============================] - 6s 3ms/sample - loss: 86.6937 - acc: 42.7993 - mean_squared_error: 43.7026 - val_loss: 247.9068 - val_acc: 0.4292 - val_mean_squared_error: 124.1680\n",
            "Epoch 6/30\n",
            "2100/2140 [============================>.] - ETA: 0s - loss: 253.9684 - acc: 100.0723 - mean_squared_error: 127.3364\n",
            "Epoch 00006: val_loss did not improve from 186.24956\n",
            "2140/2140 [==============================] - 6s 3ms/sample - loss: 253.4544 - acc: 126.1354 - mean_squared_error: 127.0784 - val_loss: 198.5874 - val_acc: 0.4292 - val_mean_squared_error: 99.5083\n",
            "Epoch 7/30\n",
            "2100/2140 [============================>.] - ETA: 0s - loss: 168.7688 - acc: 69.2844 - mean_squared_error: 84.7362\n",
            "Epoch 00007: val_loss improved from 186.24956 to 154.74840, saving model to face.h5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "2140/2140 [==============================] - 9s 4ms/sample - loss: 168.8516 - acc: 83.9396 - mean_squared_error: 84.7785 - val_loss: 154.7484 - val_acc: 0.4292 - val_mean_squared_error: 77.5888\n",
            "Epoch 8/30\n",
            "2100/2140 [============================>.] - ETA: 0s - loss: 106.0647 - acc: 52.1726 - mean_squared_error: 53.3841\n",
            "Epoch 00008: val_loss improved from 154.74840 to 25.98668, saving model to face.h5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "2140/2140 [==============================] - 9s 4ms/sample - loss: 104.5870 - acc: 52.8850 - mean_squared_error: 52.6418 - val_loss: 25.9867 - val_acc: 0.4292 - val_mean_squared_error: 13.2080\n",
            "Epoch 9/30\n",
            "2100/2140 [============================>.] - ETA: 0s - loss: 25.2303 - acc: 8.5683 - mean_squared_error: 12.9683\n",
            "Epoch 00009: val_loss did not improve from 25.98668\n",
            "2140/2140 [==============================] - 6s 3ms/sample - loss: 25.5852 - acc: 12.8515 - mean_squared_error: 13.1463 - val_loss: 49.6918 - val_acc: 0.4292 - val_mean_squared_error: 25.0605\n",
            "Epoch 10/30\n",
            "2100/2140 [============================>.] - ETA: 0s - loss: 41.3184 - acc: 16.7828 - mean_squared_error: 21.0114\n",
            "Epoch 00010: val_loss did not improve from 25.98668\n",
            "2140/2140 [==============================] - 6s 3ms/sample - loss: 41.4491 - acc: 20.8197 - mean_squared_error: 21.0781 - val_loss: 54.9743 - val_acc: 0.4292 - val_mean_squared_error: 27.7018\n",
            "Epoch 11/30\n",
            "2100/2140 [============================>.] - ETA: 0s - loss: 47.1357 - acc: 20.7396 - mean_squared_error: 23.9208\n",
            "Epoch 00011: val_loss did not improve from 25.98668\n",
            "2140/2140 [==============================] - 6s 3ms/sample - loss: 46.8479 - acc: 23.7003 - mean_squared_error: 23.7758 - val_loss: 30.9896 - val_acc: 0.4292 - val_mean_squared_error: 15.7094\n",
            "Epoch 12/30\n",
            "2100/2140 [============================>.] - ETA: 0s - loss: 22.0605 - acc: 9.9097 - mean_squared_error: 11.3827\n",
            "Epoch 00012: val_loss improved from 25.98668 to 20.86850, saving model to face.h5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "2140/2140 [==============================] - 9s 4ms/sample - loss: 21.9878 - acc: 11.2814 - mean_squared_error: 11.3462 - val_loss: 20.8685 - val_acc: 0.4292 - val_mean_squared_error: 10.6489\n",
            "Epoch 13/30\n",
            "2100/2140 [============================>.] - ETA: 0s - loss: 13.1176 - acc: 5.7414 - mean_squared_error: 6.9110\n",
            "Epoch 00013: val_loss did not improve from 20.86850\n",
            "2140/2140 [==============================] - 6s 3ms/sample - loss: 13.1397 - acc: 6.8523 - mean_squared_error: 6.9223 - val_loss: 21.6781 - val_acc: 0.4292 - val_mean_squared_error: 11.0537\n",
            "Epoch 14/30\n",
            "2100/2140 [============================>.] - ETA: 0s - loss: 16.7295 - acc: 7.0499 - mean_squared_error: 8.7177\n",
            "Epoch 00014: val_loss did not improve from 20.86850\n",
            "2140/2140 [==============================] - 6s 3ms/sample - loss: 16.7261 - acc: 8.6416 - mean_squared_error: 8.7160 - val_loss: 22.4998 - val_acc: 0.4292 - val_mean_squared_error: 11.4645\n",
            "Epoch 15/30\n",
            "2100/2140 [============================>.] - ETA: 0s - loss: 15.2889 - acc: 6.5751 - mean_squared_error: 7.9979\n",
            "Epoch 00015: val_loss improved from 20.86850 to 20.60504, saving model to face.h5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "2140/2140 [==============================] - 9s 4ms/sample - loss: 15.2375 - acc: 7.9280 - mean_squared_error: 7.9713 - val_loss: 20.6050 - val_acc: 0.4292 - val_mean_squared_error: 10.5171\n",
            "Epoch 16/30\n",
            "2100/2140 [============================>.] - ETA: 0s - loss: 12.2345 - acc: 5.4442 - mean_squared_error: 6.4697\n",
            "Epoch 00016: val_loss improved from 20.60504 to 17.56291, saving model to face.h5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "2140/2140 [==============================] - 9s 4ms/sample - loss: 12.1887 - acc: 6.4150 - mean_squared_error: 6.4467 - val_loss: 17.5629 - val_acc: 0.4292 - val_mean_squared_error: 8.9961\n",
            "Epoch 17/30\n",
            "2100/2140 [============================>.] - ETA: 0s - loss: 11.5125 - acc: 5.1043 - mean_squared_error: 6.1080\n",
            "Epoch 00017: val_loss did not improve from 17.56291\n",
            "2140/2140 [==============================] - 6s 3ms/sample - loss: 11.4907 - acc: 6.0576 - mean_squared_error: 6.0980 - val_loss: 17.5744 - val_acc: 0.4292 - val_mean_squared_error: 9.0018\n",
            "Epoch 18/30\n",
            "2100/2140 [============================>.] - ETA: 0s - loss: 11.3437 - acc: 4.7833 - mean_squared_error: 6.0251\n",
            "Epoch 00018: val_loss did not improve from 17.56291\n",
            "2140/2140 [==============================] - 6s 3ms/sample - loss: 11.3346 - acc: 5.9738 - mean_squared_error: 6.0197 - val_loss: 17.8133 - val_acc: 0.4292 - val_mean_squared_error: 9.1213\n",
            "Epoch 19/30\n",
            "2100/2140 [============================>.] - ETA: 0s - loss: 10.9635 - acc: 4.9175 - mean_squared_error: 5.8340\n",
            "Epoch 00019: val_loss improved from 17.56291 to 16.38490, saving model to face.h5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "2140/2140 [==============================] - 9s 4ms/sample - loss: 10.9289 - acc: 5.7855 - mean_squared_error: 5.8168 - val_loss: 16.3849 - val_acc: 0.4292 - val_mean_squared_error: 8.4071\n",
            "Epoch 20/30\n",
            "2100/2140 [============================>.] - ETA: 0s - loss: 10.6621 - acc: 4.6673 - mean_squared_error: 5.6850\n",
            "Epoch 00020: val_loss did not improve from 16.38490\n",
            "2140/2140 [==============================] - 6s 3ms/sample - loss: 10.6482 - acc: 5.6365 - mean_squared_error: 5.6767 - val_loss: 16.9312 - val_acc: 0.4292 - val_mean_squared_error: 8.6802\n",
            "Epoch 21/30\n",
            "2100/2140 [============================>.] - ETA: 0s - loss: 10.6991 - acc: 4.6171 - mean_squared_error: 5.7033\n",
            "Epoch 00021: val_loss did not improve from 16.38490\n",
            "2140/2140 [==============================] - 6s 3ms/sample - loss: 10.6735 - acc: 5.6556 - mean_squared_error: 5.6901 - val_loss: 16.7456 - val_acc: 0.4292 - val_mean_squared_error: 8.5874\n",
            "Epoch 22/30\n",
            "2100/2140 [============================>.] - ETA: 0s - loss: 10.3690 - acc: 4.5817 - mean_squared_error: 5.5365\n",
            "Epoch 00022: val_loss did not improve from 16.38490\n",
            "2140/2140 [==============================] - 6s 3ms/sample - loss: 10.3863 - acc: 5.4911 - mean_squared_error: 5.5456 - val_loss: 16.4720 - val_acc: 0.4292 - val_mean_squared_error: 8.4506\n",
            "Epoch 23/30\n",
            "2100/2140 [============================>.] - ETA: 0s - loss: 10.4370 - acc: 4.6126 - mean_squared_error: 5.5710\n",
            "Epoch 00023: val_loss did not improve from 16.38490\n",
            "2140/2140 [==============================] - 6s 3ms/sample - loss: 10.4491 - acc: 5.5248 - mean_squared_error: 5.5770 - val_loss: 17.0519 - val_acc: 0.4292 - val_mean_squared_error: 8.7405\n",
            "Epoch 24/30\n",
            "2100/2140 [============================>.] - ETA: 0s - loss: 10.4547 - acc: 4.7389 - mean_squared_error: 5.5803\n",
            "Epoch 00024: val_loss did not improve from 16.38490\n",
            "2140/2140 [==============================] - 6s 3ms/sample - loss: 10.4624 - acc: 5.5340 - mean_squared_error: 5.5841 - val_loss: 16.7146 - val_acc: 0.4292 - val_mean_squared_error: 8.5719\n",
            "Epoch 25/30\n",
            "2100/2140 [============================>.] - ETA: 0s - loss: 10.2584 - acc: 4.5666 - mean_squared_error: 5.4829\n",
            "Epoch 00025: val_loss did not improve from 16.38490\n",
            "2140/2140 [==============================] - 6s 3ms/sample - loss: 10.2780 - acc: 5.4370 - mean_squared_error: 5.4922 - val_loss: 16.4946 - val_acc: 0.4292 - val_mean_squared_error: 8.4619\n",
            "Epoch 26/30\n",
            "2100/2140 [============================>.] - ETA: 0s - loss: 10.2437 - acc: 4.4287 - mean_squared_error: 5.4732\n",
            "Epoch 00026: val_loss did not improve from 16.38490\n",
            "2140/2140 [==============================] - 6s 3ms/sample - loss: 10.2462 - acc: 5.4288 - mean_squared_error: 5.4753 - val_loss: 16.8907 - val_acc: 0.4292 - val_mean_squared_error: 8.6600\n",
            "Epoch 27/30\n",
            "2100/2140 [============================>.] - ETA: 0s - loss: 10.2090 - acc: 4.3551 - mean_squared_error: 5.4577\n",
            "Epoch 00027: val_loss improved from 16.38490 to 16.26010, saving model to face.h5\n",
            "INFO:tensorflow:Copying TPU weights to the CPU\n",
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file.You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n",
            "2140/2140 [==============================] - 9s 4ms/sample - loss: 10.2477 - acc: 5.4123 - mean_squared_error: 5.4769 - val_loss: 16.2601 - val_acc: 0.4292 - val_mean_squared_error: 8.3447\n",
            "Epoch 28/30\n",
            "2100/2140 [============================>.] - ETA: 0s - loss: 10.2178 - acc: 4.4709 - mean_squared_error: 5.4612\n",
            "Epoch 00028: val_loss did not improve from 16.26010\n",
            "2140/2140 [==============================] - 6s 3ms/sample - loss: 10.2534 - acc: 5.4165 - mean_squared_error: 5.4795 - val_loss: 16.5119 - val_acc: 0.4292 - val_mean_squared_error: 8.4705\n",
            "Epoch 29/30\n",
            "2100/2140 [============================>.] - ETA: 0s - loss: 10.2295 - acc: 4.5747 - mean_squared_error: 5.4675\n",
            "Epoch 00029: val_loss did not improve from 16.26010\n",
            "2140/2140 [==============================] - 6s 3ms/sample - loss: 10.2355 - acc: 5.4222 - mean_squared_error: 5.4704 - val_loss: 16.2920 - val_acc: 0.4292 - val_mean_squared_error: 8.3606\n",
            "Epoch 30/30\n",
            "2100/2140 [============================>.] - ETA: 0s - loss: 10.1832 - acc: 4.5106 - mean_squared_error: 5.4448\n",
            "Epoch 00030: val_loss did not improve from 16.26010\n",
            "2140/2140 [==============================] - 6s 3ms/sample - loss: 10.1923 - acc: 5.4000 - mean_squared_error: 5.4496 - val_loss: 16.3068 - val_acc: 0.4292 - val_mean_squared_error: 8.3680\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9uYbH1hSoclh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "learning_rate=0.001\n",
        "model_drop_na=model\n",
        "opt = tf.train.AdamOptimizer(learning_rate)\n",
        "model_drop_na.compile(optimizer=opt, loss='mean_squared_error', metrics=['acc','mse'])\n",
        "#save_model(model_drop_na,'124446.model')\n",
        "tpu_model = tf.contrib.tpu.keras_to_tpu_model(\n",
        "    model_drop_na,\n",
        "    strategy=tf.contrib.tpu.TPUDistributionStrategy(\n",
        "        tf.contrib.cluster_resolver.TPUClusterResolver(TPU_ADDRESS)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y36xr1VWioTO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_history(history):\n",
        "  pyplot=plt\n",
        "  pyplot.subplot(211)\n",
        "  pyplot.title('Loss')\n",
        "  pyplot.plot(history.history['loss'], label='train')\n",
        "  pyplot.plot(history.history['val_loss'], label='test')\n",
        "  pyplot.legend()\n",
        "  # plot mse during training\n",
        "  pyplot.subplot(212)\n",
        "  pyplot.title('Mean Squared Error')\n",
        "  #pyplot.plot(history.history['mean_squared_error'], label='train')\n",
        "  #pyplot.plot(history.history['val_mean_squared_error'], label='test')\n",
        "  pyplot.plot(history.history['acc'], label='train')\n",
        "  pyplot.plot(history.history['val_acc'], label='test')\n",
        "  pyplot.legend()\n",
        "  pyplot.show()\n",
        "plot_history(history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dEZQfNHl5PV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# evaluate the model\n",
        "train_mse = model_drop_na.evaluate(train_images_clean, train_features_clean, verbose=0)\n",
        "test_mse = model_drop_na.evaluate(train_images_cnn, train_features_cnn, verbose=0)\n",
        "print('Train: %.3f, Test: %.3f' % (train_mse, test_mse))\n",
        "# plot loss during training"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6CqGLzNis-XH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_test_single(predicted_points,image, index):\n",
        "  '''shows predicted features on image\n",
        "  \n",
        "  requires:\n",
        "  - test_images'''\n",
        "  x_points = []\n",
        "  y_points = []\n",
        "\n",
        "  # split into x coords and y coords\n",
        "  for i in range(15):\n",
        "    x_points.append(predicted_points[i*2])\n",
        "    y_points.append(predicted_points[i*2+1])\n",
        "    \n",
        "  ax = plt.subplot(1,1,1)\n",
        "  ax.imshow(image.reshape(96,96),cmap='gray')\n",
        "  #ax.get_xaxis().set_visible(False)\n",
        "  #ax.get_yaxis().set_visible(False)\n",
        "  ax.scatter(x=x_points, y=y_points, c='r', s=20)\n",
        "index=200\n",
        "predicted_points=model_drop_na.predict(test_images_cnn[index].reshape(1,96,96,1), batch_size=1)\n",
        "\n",
        "plot_test_single(predicted_points[0],test_images_cnn[index], index)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qp57tR29YVeu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install impyute\n",
        "from impyute.imputation.cs import mice\n",
        "\n",
        "# start the MICE training\n",
        "\n",
        "imputed_training_mice=mice(train_features_cnn.astype(float))\n",
        "\n",
        "#(array([ 0,  2,  4,  6,  8, 10, 12, 14, 20, 22, 24]), array([   0,  210, 1652, 1643, 1636, 1620, 1866, 1747, 2153, 2284, 2289]), array([2140,   87,   28,    9,    8,    3,    5,    2,    2, 4755,   10]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "W2fvKlspxrUP",
        "colab": {}
      },
      "source": [
        "image=2284; plot_test_single(train_features_cnn[image],train_images_cnn[image], image)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#imputed1= np.array([image.astype(object) for image in imputed_training_mice])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iY5qGE4RA51G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_imputed=model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wVX2nhJKX3Fn",
        "colab": {}
      },
      "source": [
        "\n",
        "Adam=optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
        "\n",
        "\n",
        "file_checkpoint_name='face_model-adam-mse-0-lr005-mice.h5'\n",
        "\n",
        "\n",
        "model_imputed.compile(optimizer=Adam, loss=\"mean_squared_error\", metrics=['acc'])\n",
        "\n",
        "checkpointer = callbacks.ModelCheckpoint(filepath=file_checkpoint_name, verbose=1, save_best_only=True)\n",
        "\n",
        "epochs = 30\n",
        "\n",
        "history = model_imputed.fit(train_images_cnn, imputed1, validation_split=0.2, shuffle=True, epochs=epochs, batch_size=30, callbacks=[checkpointer], verbose=1)\n",
        "\n",
        "#files.download(file_checkpoint_name) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7knNiK4YTCO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predicted_points=model_imputed.predict(test_images_cnn[200].reshape(1,96,96,1), batch_size=1)\n",
        "_, train_mse = model_drop_na.evaluate(train_images_clean, train_features_clean, verbose=0)\n",
        "_, test_mse = model_drop_na.evaluate(train_images_cnn, train_features_cnn, verbose=0)\n",
        "plot_test_single(predicted_points[0],test_images_cnn[200], index)\n",
        "print('Train: %.3f, Test: %.3f' % (train_mse, test_mse))\n",
        "files.download(file_checkpoint_name) "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}